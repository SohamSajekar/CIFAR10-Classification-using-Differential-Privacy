{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d0b2ea",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074e486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from absl import flags\n",
    "import tensorflow as tf\n",
    "import tensorflow_privacy\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "from keras.layers import Input, Dense, Add\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n",
    "%matplotlib inline\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae37ef",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecc27bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: (50000, 32, 32, 3) (50000, 10)\n",
      "testing: (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loading cifar10 image dataset\n",
    "data_train, data_test = cifar10.load_data()\n",
    "x_train, y_train = data_train\n",
    "x_test, y_test = data_test\n",
    "\n",
    "# Normalizing pixel values of images\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Flattening images in dataset\n",
    "y_train = y_train.flatten().reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.flatten().reshape(y_test.shape[0], 1)\n",
    "\n",
    "# One hot encoding of labels/target column\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(\"training:\", x_train.shape, y_train.shape)\n",
    "print(\"testing:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "id": "dd78ba01",
   "metadata": {},
   "source": [
    "### Model3: Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 40\n",
    "batch_size = 1250\n",
    "l2_norm_clip = 1.5\n",
    "noise_multiplier = 1.3\n",
    "num_microbatches = 250\n",
    "learning_rate = 0.25\n",
    "delta = 1e-5\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "    raise ValueError('Batch size should be an integer multiple of the number of microbatches')\n",
    "    \n",
    "# Compute RDP\n",
    "orders = [1 + x / 10. for x in range(1, 100)] + list(range(12, 64))\n",
    "rdp = compute_rdp(q = batch_size / 50000,\n",
    "                  noise_multiplier = noise_multiplier,\n",
    "                  steps = epochs * 50000 // batch_size,\n",
    "                  orders=orders)\n",
    "# Calculate epsilon\n",
    "epsilon = get_privacy_spent(orders, rdp, target_delta=delta)[0]\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 5, strides=1, padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "#     tf.keras.layers.ReLU(max_value = 50, negative_slope = 1.2),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, 5, strides=1, padding='valid', activation='relu'),\n",
    "#     tf.keras.layers.ReLU(max_value = 50, negative_slope = 1.2),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, 3, strides=2, padding='valid', activation='relu'),\n",
    "#     tf.keras.layers.ReLU(max_value = 50, negative_slope = 1.2),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "#     tf.keras.layers.ReLU(max_value = 50, negative_slope = 1.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f979ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer (dp-sgd) \n",
    "# optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "#     l2_norm_clip=l2_norm_clip,\n",
    "#     noise_multiplier=noise_multiplier,\n",
    "#     num_microbatches=num_microbatches,\n",
    "#     learning_rate=learning_rate)\n",
    "\n",
    "# define optimizer (dp-adam)\n",
    "optimizer = tensorflow_privacy.DPKerasAdamOptimizer(\n",
    "    l2_norm_clip, noise_multiplier, num_microbatches)\n",
    "\n",
    "# define loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9b4c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "# Train model\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf41bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
>>>>>>> Stashed changes
   "id": "69813367",
   "metadata": {},
   "source": [
    "### Model1: Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ed758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 20\n",
    "batch_size = 500\n",
    "\n",
    "l2_norm_clip = 1.5\n",
    "noise_multiplier = 1.3\n",
    "num_microbatches = 250\n",
    "learning_rate = 0.25\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "    raise ValueError('Batch size should be an integer multiple of the number of microbatches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc133894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 8,\n",
    "                           strides=2,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(2, 1),\n",
    "    tf.keras.layers.Conv2D(32, 4,\n",
    "                           strides=2,\n",
    "                           padding='valid',\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 1),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer (dp-sgd) \n",
    "optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches,\n",
    "    learning_rate=learning_rate)\n",
    "# define loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0fb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "# Train model\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad27007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate privacy performance\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=x_train.shape[0],\n",
    "                                              batch_size=batch_size,\n",
    "                                              noise_multiplier=noise_multiplier,\n",
    "                                              epochs=epochs,\n",
    "                                              delta=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d91bb",
   "metadata": {},
   "source": [
    "### Model2: VGG with transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e42f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 35\n",
    "batch_size = 500\n",
    "\n",
    "l2_norm_clip = 1.5\n",
    "noise_multiplier = 1.3\n",
    "num_microbatches = 250\n",
    "learning_rate = 0.25\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "    raise ValueError('Batch size should be an integer multiple of the number of microbatches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47989ed6",
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 20:28:24.221689: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-13 20:28:24.221956: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-03-13 20:28:24.234984: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-13 20:28:24.235621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-13 20:28:24.267077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-13 20:28:24.447433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "#Building a VGG model with pretrained weights\n",
    "\n",
    "vgg_model=tf.keras.Sequential()\n",
    "\n",
    "#https://keras.io/api/applications/vgg/#vgg16-function\n",
    "#https://keras.io/guides/transfer_learning/\n",
    "#https://chroniclesofai.com/transfer-learning-with-keras-resnet-50/\n",
    "pre_vgg_model=tf.keras.applications.VGG16(include_top=False,weights=\"imagenet\",\n",
    "                                          classes=10,pooling=max,input_shape=(32,32,3))\n",
    "pre_vgg_model.trainable=False\n",
    "vgg_model.add(pre_vgg_model)\n",
    "vgg_model.add(tf.keras.layers.Flatten())\n",
    "vgg_model.add(tf.keras.layers.Dense(512, activation='tanh'))\n",
    "vgg_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d190e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define optimizer (dp-sgd) \n",
    "vgg_optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches,\n",
    "    learning_rate=learning_rate)\n",
    "# define loss function\n",
    "vgg_loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073901b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "vgg_model.compile(optimizer=vgg_optimizer, loss=vgg_loss, metrics=['accuracy'])\n",
    "# Train model\n",
    "vgg_model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_multiplier = FLAGS.noise_multiplier\n",
    "# sampling_probability = FLAGS.batch_size / 60000\n",
    "# steps = FLAGS.epochs * 60000 // FLAGS.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5da992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from absl import app\n",
    "# from absl import flags\n",
    "# from absl import logging\n",
    "# FLAGS = flags.FLAGS\n",
    "orders = [1 + x / 10. for x in range(1, 100)] + list(range(12, 64))\n",
    "rdp = compute_rdp(q = batch_size / 50000,\n",
    "                  noise_multiplier = noise_multiplier,\n",
    "                  steps = epochs * 50000 // batch_size,\n",
    "                  orders=orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae030b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = get_privacy_spent(orders, rdp, target_delta=1e-5)[0]\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573f77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53bc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1367e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d82bc59",
   "metadata": {},
   "source": [
    "### Model: Custom ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a945b483",
   "metadata": {},
   "outputs": [
    {
<<<<<<< Updated upstream
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanikakatekar/miniforge3/envs/san_tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
=======
     "data": {
      "text/plain": [
       "4.980956406486334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 50\n",
    "batch_size = 1250\n",
    "l2_norm_clip = 1.5\n",
    "noise_multiplier = 1.3\n",
    "num_microbatches = 250\n",
    "learning_rate = 0.25\n",
    "delta = 1e-5\n",
    "\n",
    "if batch_size % num_microbatches != 0:\n",
    "    raise ValueError('Batch size should be an integer multiple of the number of microbatches')\n",
    "    \n",
    "# Compute RDP\n",
    "orders = [1 + x / 10. for x in range(1, 100)] + list(range(12, 64))\n",
    "rdp = compute_rdp(q = batch_size / 50000,\n",
    "                  noise_multiplier = noise_multiplier,\n",
    "                  steps = epochs * 50000 // batch_size,\n",
    "                  orders=orders)\n",
    "# Calculate epsilon\n",
    "epsilon = get_privacy_spent(orders, rdp, target_delta=delta)[0]\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c59fdf",
   "metadata": {},
   "outputs": [
>>>>>>> Stashed changes
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 64)   1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 5, 5, 64)     0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 5, 5, 64)     36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " group_normalization (GroupNorm  (None, 5, 5, 64)    128         ['conv2d_1[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 5, 5, 64)     36928       ['group_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 5, 5, 64)     0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 5, 5, 64)     36928       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " group_normalization_1 (GroupNo  (None, 5, 5, 64)    128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 5, 5, 64)     36928       ['group_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 5, 5, 64)     0           ['add[0][0]',                    \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 5, 5, 64)     36928       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " group_normalization_2 (GroupNo  (None, 5, 5, 64)    128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 5, 5, 64)     36928       ['group_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 5, 5, 64)     0           ['add_1[0][0]',                  \n",
      "                                                                  'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 5, 5, 64)     36928       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " group_normalization_3 (GroupNo  (None, 5, 5, 64)    128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 5, 5, 64)     36928       ['group_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 5, 5, 64)     0           ['add_2[0][0]',                  \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 5, 5, 64)     36928       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " group_normalization_4 (GroupNo  (None, 5, 5, 64)    128         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 5, 5, 64)     36928       ['group_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 5, 5, 64)     0           ['add_3[0][0]',                  \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 2, 2, 64)    0           ['add_4[0][0]']                  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           16448       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           650         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 388,810\n",
      "Trainable params: 388,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Resnet 12 architecture: https://www.researchgate.net/publication/329954455_Short-Term_Load_Forecasting_based_on_ResNet_and_LSTM\n",
    "\n",
    "input_i = Input(shape=(32,32,3))\n",
    "x1 = tf.keras.layers.Conv2D(64, 3, strides=2, padding='same', activation='relu')(input_i)\n",
    "x2 = tf.keras.layers.MaxPool2D((3,3))(x1)\n",
    "x3 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x2)\n",
    "x3 = tfa.layers.GroupNormalization(groups=64,axis=3)(x3)\n",
    "x4 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='tanh')(x3)\n",
    "x_add1 = Add()([x2,x4])\n",
    "x5 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x_add1)\n",
    "x5 = tfa.layers.GroupNormalization(groups=64,axis=3)(x5)\n",
    "x6 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='tanh')(x5)\n",
    "x_add2 = Add()([x_add1,x6])\n",
    "x6 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x_add2)\n",
    "x6 = tfa.layers.GroupNormalization(groups=64,axis=3)(x6)\n",
    "x7 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x6)\n",
    "x_add3 = Add()([x_add2,x7])\n",
    "x8 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x_add3)\n",
    "x8 = tfa.layers.GroupNormalization(groups=64,axis=3)(x8)\n",
    "x9 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x8)\n",
    "x_add4 = Add()([x_add3,x9])\n",
    "x10 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu')(x_add4)\n",
    "x10 = tfa.layers.GroupNormalization(groups=64,axis=3)(x10)\n",
    "x11 = tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='tanh')(x10)\n",
    "x_add5 = Add()([x_add4,x11])\n",
    "x12 = tf.keras.layers.AvgPool2D((2,2))(x_add5)\n",
    "x_flatten= tf.keras.layers.Flatten()(x12)\n",
    "x_dense1=tf.keras.layers.Dense(64, activation='tanh')(x_flatten)\n",
    "output_o = tf.keras.layers.Dense(10, activation='softmax')(x_dense1)\n",
    "\n",
    "res12_m= Model(inputs= input_i, outputs=output_o)\n",
    "res12_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f02c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer (dp-sgd) \n",
    "optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches,\n",
    "    learning_rate=learning_rate)\n",
    "# define loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c035119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "2022-03-13 20:28:37.675902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
=======
      "/Users/sanikakatekar/miniforge3/envs/san_tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Epoch 1/35\n"
=======
      "Train on 50000 samples, validate on 10000 samples\n",
      "Metal device set to: Apple M1\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "2022-03-13 20:28:37.934316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-13 20:28:38.002724: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-13 20:28:38.060543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
=======
      "2022-03-20 21:51:52.125922: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-20 21:51:52.126239: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-03-20 21:51:54.961180: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-20 21:51:55.007751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-20 21:51:57.565037: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "50000/50000 [==============================] - ETA: 0s - loss: 1.9557 - acc: 0.3124"
=======
      "Epoch 1/50\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "/Users/sanikakatekar/miniforge3/envs/san_tf/lib/python3.9/site-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2022-03-13 20:34:42.092718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
=======
      "2022-03-20 21:51:58.101394: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-20 21:51:58.522990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "50000/50000 [==============================] - 371s 7ms/sample - loss: 1.9557 - acc: 0.3124 - val_loss: 1.7407 - val_acc: 0.3929\n",
      "Epoch 2/35\n",
      "50000/50000 [==============================] - 348s 7ms/sample - loss: 1.6445 - acc: 0.4328 - val_loss: 1.5921 - val_acc: 0.4352\n",
      "Epoch 3/35\n",
      "50000/50000 [==============================] - 350s 7ms/sample - loss: 1.5420 - acc: 0.4656 - val_loss: 1.5152 - val_acc: 0.4680\n",
      "Epoch 4/35\n",
      "50000/50000 [==============================] - 351s 7ms/sample - loss: 1.4829 - acc: 0.4827 - val_loss: 1.4788 - val_acc: 0.4807\n",
      "Epoch 5/35\n",
      "50000/50000 [==============================] - 352s 7ms/sample - loss: 1.4452 - acc: 0.4961 - val_loss: 1.4468 - val_acc: 0.4898\n",
      "Epoch 6/35\n",
      "50000/50000 [==============================] - 352s 7ms/sample - loss: 1.4220 - acc: 0.5041 - val_loss: 1.4285 - val_acc: 0.4984\n",
      "Epoch 7/35\n",
      "50000/50000 [==============================] - 349s 7ms/sample - loss: 1.4011 - acc: 0.5139 - val_loss: 1.4108 - val_acc: 0.5088\n",
      "Epoch 8/35\n",
      "50000/50000 [==============================] - 350s 7ms/sample - loss: 1.3849 - acc: 0.5215 - val_loss: 1.4077 - val_acc: 0.5088\n",
      "Epoch 9/35\n",
      "50000/50000 [==============================] - 351s 7ms/sample - loss: 1.3694 - acc: 0.5264 - val_loss: 1.4018 - val_acc: 0.5127\n",
      "Epoch 10/35\n",
      "50000/50000 [==============================] - 353s 7ms/sample - loss: 1.3598 - acc: 0.5294 - val_loss: 1.3851 - val_acc: 0.5187\n",
      "Epoch 11/35\n",
      "50000/50000 [==============================] - 354s 7ms/sample - loss: 1.3484 - acc: 0.5357 - val_loss: 1.3750 - val_acc: 0.5211\n",
      "Epoch 12/35\n",
      "50000/50000 [==============================] - 361s 7ms/sample - loss: 1.3390 - acc: 0.5362 - val_loss: 1.3677 - val_acc: 0.5245\n",
      "Epoch 13/35\n",
      "50000/50000 [==============================] - 356s 7ms/sample - loss: 1.3325 - acc: 0.5401 - val_loss: 1.3692 - val_acc: 0.5261\n",
      "Epoch 14/35\n",
      "50000/50000 [==============================] - 356s 7ms/sample - loss: 1.3291 - acc: 0.5416 - val_loss: 1.3642 - val_acc: 0.5300\n",
      "Epoch 15/35\n",
      "50000/50000 [==============================] - 359s 7ms/sample - loss: 1.3223 - acc: 0.5435 - val_loss: 1.3515 - val_acc: 0.5323\n",
      "Epoch 16/35\n",
      "50000/50000 [==============================] - 368s 7ms/sample - loss: 1.3165 - acc: 0.5490 - val_loss: 1.3549 - val_acc: 0.5336\n",
      "Epoch 17/35\n",
      "50000/50000 [==============================] - 368s 7ms/sample - loss: 1.3149 - acc: 0.5504 - val_loss: 1.3529 - val_acc: 0.5330\n",
      "Epoch 18/35\n",
      "50000/50000 [==============================] - 363s 7ms/sample - loss: 1.3089 - acc: 0.5519 - val_loss: 1.3516 - val_acc: 0.5331\n",
      "Epoch 19/35\n",
      "50000/50000 [==============================] - 361s 7ms/sample - loss: 1.3055 - acc: 0.5529 - val_loss: 1.3464 - val_acc: 0.5337\n",
      "Epoch 20/35\n",
      "50000/50000 [==============================] - 358s 7ms/sample - loss: 1.3061 - acc: 0.5545 - val_loss: 1.3564 - val_acc: 0.5314\n",
      "Epoch 21/35\n",
      "50000/50000 [==============================] - 357s 7ms/sample - loss: 1.3041 - acc: 0.5545 - val_loss: 1.3536 - val_acc: 0.5354\n",
      "Epoch 22/35\n",
      "50000/50000 [==============================] - 354s 7ms/sample - loss: 1.3016 - acc: 0.5564 - val_loss: 1.3422 - val_acc: 0.5399\n",
      "Epoch 23/35\n",
      "50000/50000 [==============================] - 353s 7ms/sample - loss: 1.2996 - acc: 0.5571 - val_loss: 1.3522 - val_acc: 0.5361\n",
      "Epoch 24/35\n",
      "50000/50000 [==============================] - 353s 7ms/sample - loss: 1.2972 - acc: 0.5582 - val_loss: 1.3405 - val_acc: 0.5402\n",
      "Epoch 25/35\n",
      "50000/50000 [==============================] - 355s 7ms/sample - loss: 1.2934 - acc: 0.5587 - val_loss: 1.3411 - val_acc: 0.5437\n",
      "Epoch 26/35\n",
      "50000/50000 [==============================] - 357s 7ms/sample - loss: 1.2932 - acc: 0.5602 - val_loss: 1.3447 - val_acc: 0.5405\n",
      "Epoch 27/35\n",
      "50000/50000 [==============================] - 362s 7ms/sample - loss: 1.2929 - acc: 0.5613 - val_loss: 1.3490 - val_acc: 0.5410\n",
      "Epoch 28/35\n",
      "50000/50000 [==============================] - 359s 7ms/sample - loss: 1.2933 - acc: 0.5615 - val_loss: 1.3385 - val_acc: 0.5425\n",
      "Epoch 29/35\n",
      "50000/50000 [==============================] - 358s 7ms/sample - loss: 1.2871 - acc: 0.5621 - val_loss: 1.3359 - val_acc: 0.5456\n",
      "Epoch 30/35\n",
      "50000/50000 [==============================] - 368s 7ms/sample - loss: 1.2910 - acc: 0.5609 - val_loss: 1.3334 - val_acc: 0.5490\n",
      "Epoch 31/35\n",
      "50000/50000 [==============================] - 361s 7ms/sample - loss: 1.2941 - acc: 0.5609 - val_loss: 1.3409 - val_acc: 0.5485\n",
      "Epoch 32/35\n",
      "50000/50000 [==============================] - 364s 7ms/sample - loss: 1.2909 - acc: 0.5634 - val_loss: 1.3452 - val_acc: 0.5427\n",
      "Epoch 33/35\n",
      "50000/50000 [==============================] - 360s 7ms/sample - loss: 1.2915 - acc: 0.5635 - val_loss: 1.3368 - val_acc: 0.5455\n",
      "Epoch 34/35\n",
      "50000/50000 [==============================] - 359s 7ms/sample - loss: 1.2892 - acc: 0.5639 - val_loss: 1.3301 - val_acc: 0.5465\n",
      "Epoch 35/35\n",
      "50000/50000 [==============================] - 359s 7ms/sample - loss: 1.2895 - acc: 0.5641 - val_loss: 1.3356 - val_acc: 0.5475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1571f5a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
=======
      " 2500/50000 [>.............................] - ETA: 9:48:14 - loss: 2.6228 - acc: 0.0776 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1m/99yy5m3128vbnmcslwm71z4m0000gn/T/ipykernel_80540/2940781589.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mres12_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m res12_m.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/san_tf/lib/python3.9/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/san_tf/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     return fit_loop(\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/san_tf/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/san_tf/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4273\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4275\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   4276\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   4277\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/san_tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
>>>>>>> Stashed changes
    }
   ],
   "source": [
    "# Compile model\n",
    "res12_m.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "# Train model\n",
    "res12_m.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c0099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6149a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce379593",
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4127950269222396"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = get_privacy_spent(orders, rdp, target_delta=1e-5)[0]\n",
    "epsilon"
   ]
=======
   "outputs": [],
   "source": []
>>>>>>> Stashed changes
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "id": "f0655924",
=======
   "id": "3a2690f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96e5a9",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea0ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e90e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e23d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d695eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_wo_transfer=tf.keras.applications.VGG16(include_top=True,weights=None,classes=10,pooling=max,input_shape=(32,32,3))\n",
    "vgg_wo_transfer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c56375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define optimizer (dp-sgd) \n",
    "vgg_optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches,\n",
    "    learning_rate=learning_rate)\n",
    "# define loss function\n",
    "vgg_loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9b220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 13:02:33.937481: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-13 13:02:34.780027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 13:02:35.329703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-13 13:02:35.499104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "vgg_wo_transfer.compile(optimizer=vgg_optimizer, loss=vgg_loss, metrics=['accuracy'])\n",
    "# Train model\n",
    "vgg_wo_transfer.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba636e0",
   "metadata": {},
   "source": [
    "### Model3: HOG classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220c293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8335f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb734b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
